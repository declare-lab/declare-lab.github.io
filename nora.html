<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Hugo 0.66.0" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://fonts.googleapis.com/css?family=Roboto:300,400,600" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
  <!-- <link rel="stylesheet" href="../css/normalize.css"> -->
  <!-- <link rel="stylesheet" href="../css/skeleton.css"> -->
  <!-- <link rel="stylesheet" href="../css/custom.css"> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="alternate" href="index.xml" type="application/rss+xml" title="Speech Research">
  <!-- <link rel="shortcut icon" href="favicon.png" type="image/x-icon" /> -->
  <title>NORA: A Small Open-Sourced Generalist Vision Language Action Model for Embodied Tasks</title>
<style>
figcaption {
	color: inherit;
	font-size: inherit;
	font-family: inherit;
}
table {
	font-family: inherit;
	font-size: inherit;
}
thead {
	background-color: inherit;
	border-bottom: inherit;
}
h2 {
	font-size: 1.5rem;
}
.container {
	color: #061E61;
}
</style>
</head>

  <font size="5">

    <div class="container">

      <header role="banner">

      </header>
      <main role="main">
        <article itemscope itemtype="https://schema.org/BlogPosting">
          <br>
          <h1 itemprop="headline" align="center">
            <font color="000093" size="7">NORA: A Small Open-Sourced Generalist Vision Language Action Model for Embodied Tasks</font>
          </h1>
          <br>
          <p style="line-height:1" align="center"><b>
              <font color="061E61">Chia-Yu Hung<sup>1</sup>, Qi Sun<sup>1</sup>, Pengfei Hong<sup>1</sup></font>
            </b></p>
          <p style="line-height:1" align="center"><b>
              <font color="061E61">Amir Zadeh<sup>2</sup>, Chuan Li<sup>2</sup></font>
            </b></p>
          <p style="line-height:1" align="center"><b>
              <font color="061E61">U-Xuan Tan<sup>1</sup>, Navonil Majumder<sup>1</sup>, Soujanya Poria<sup>1</sup></font>
            </b></p>
          <p style="line-height:0.6" align="center">
            <font color="061E61"><sup>1</sup>DeCLaRe Lab, Singapore University of Technology and Design, Singapore</font>
          </p>
          <p style="line-height:0.6" align="center">
            <font color="061E61"><sup>2</sup>Lambda Labs</font>
          </p>
 <!--          <p style="line-height:0.6" align="center">
            <font color="061E61"> <sup>2</sup>Department of EEE, Imperial College London, London, UK</font>
          </p>
          <p style="line-height:1" align="center">
            <font color="061E61"><sup>*</sup>Equal Contribution</font>
          </p> -->
          <section itemprop="entry-text">
            <br>
            <div class="container">
              <center>
                <p><a href="https://arxiv.org/abs/2504.19854">[Paper on ArXiv]</a>&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/declare-lab/nora">[Code on GitHub]</a>&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://huggingface.co/collections/declare-lab/nora-6811ba3e820ef362d9eca281">[Hugging Face]</a></p>
              </center>
            </div>
            <h2 id="abstract">
              <font color="000093">Abstract</font>
            </h2>
            <p style="text-align: justify;">
              <font color="061E61">Existing Visual-Language-Action (VLA) models have shown promising performance in zero-shot scenarios, demonstrating impressive task execution and reasoning capabilities. However, a significant challenge arises from the limitations of visual encoding, which can result in failures during tasks such as object grasping. Moreover, these models typically suffer from high computational overhead due to their large sizes, often exceeding 7B parameters. While these models excel in reasoning and task planning, the substantial computational overhead they incur makes them impractical for real-time robotic environments, where speed and efficiency are paramount. Given the common practice of fine-tuning VLA models for specific tasks, there is a clear need for a smaller, more efficient model that can be fine-tuned on consumer-grade GPUs.  To address the limitations of existing VLA models, we propose NORA, a 3B-parameter model designed to reduce computational overhead while maintaining strong task performance. NORA adopts the Qwen-2.5-VL-3B multimodal model as the backbone, leveraging its superior visual-semantic understanding to enhance visual reasoning and action grounding. Additionally, our NORA is trained on 970k real-world robot demonstrations and equipped with the FAST+ tokenizer for efficient action sequence generation. Experimental results demonstrate that NORA outperforms existing large-scale VLA models, achieving better task performance with significantly reduced computational overhead, making it a more practical solution for real-time robotic autonomy.</font>
            </p>

            <!-- <h2 id="note"> -->
            <!--   <font color="000093">Note</font> -->
            <!-- </h2> -->
            <!-- <li> -->
            <!--   <font color="061E61"> TANGO generates text-conditional sound effects, including human speech, and music.</font> -->
            <!-- </li> -->
            <!-- <li> -->
            <!--   <font color="061E61"> The LDM is trained on a four A6000 GPUs, with text supervision from instruction tuned LLM -- FLAN-T5. </font> -->
            <!-- </li> -->
            <!-- <li> -->
            <!--   <font color="061E61"> Despite training TANGO's LDM with 63x less data, it manages to produce superior sound quality to the baselines</font> -->
            <!-- </li> -->

            <br>
            <figure>
              <p align="center"><img src="../NORA.png" width="100%" class="center" /></p>
              <figcaption>
                <p style="text-align: justify">
		<font color="061E61"><b>Figure 1:</b> NORA, as depicted in this figure, has three major components: (i) image encoder, (ii) vision language model, and (iii) FAST+ action tokenizer. The image encoder encodes the current state of the environment. Subsequently, the VLM predicts the next action in order to accomplish the input goal, given the current state. Thereafter, FAST+ decodes the VLM output tokens into actionable robot tokens.</font>
                </p>
              </figcaption>
            </figure>


            <br>

            <p id="demos"><b>
                <font color="061E61">Examples of NORA in action:</font>
              </b></p>

            <table class="table" align="center" style="table-layout: fixed;word-break:break-word">
                <tr>
                  <td scope="col" width="33%">
                    <font color="061E61"><i>Task Instruction</i></font>
                  </td>
                  <td scope="col" width="66%">
                    <font color="061E61"><i>Policy Execution</i></font>
                  </td>
                </tr>
              <tbody>
                <tr>
                  <td scope="row">Put the blue cube on the plate</td>
                  <td>
                    <iframe width="640" height="360"
                      src="https://www.youtube.com/embed/vhRcvLRs5lI" 
                      frameborder="0" allowfullscreen>
                    </iframe>
                  </td>
                </tr>
                <tr>
                  <td scope="row">Put the corn and carrot in pan</td>
                  <td>
                    <iframe width="640" height="360"
                      src="https://www.youtube.com/embed/k3seqSaGftU"
                      frameborder="0" allowfullscreen>
                    </iframe>
                  </td>
                </tr>
                <tr>
                  <td scope="row">Put banana and carrot in pot</td>
                  <td>
                    <iframe width="640" height="360"
                      src="https://www.youtube.com/embed/8RzuMsOkw2o"
                      frameborder="0" allowfullscreen>
                    </iframe>
                  </td>
                </tr>
                <tr>
                  <td scope="row">Move the banana close to the pan</td>
                  <td>
                    <iframe width="640" height="360"
                      src="https://www.youtube.com/embed/AFZP3-1MEvY"
                      frameborder="0" allowfullscreen>
                    </iframe>
                  </td>
                </tr>
                <tr>
                  <td scope="row">Put carrot in the pot</td>
                  <td>
                    <iframe width="640" height="360"
                      src="https://www.youtube.com/embed/L9eydFNtEWI"
                      frameborder="0" allowfullscreen>
                    </iframe>
                  </td>
                </tr>
                <tr>
                  <td scope="row">Put the pink toy at the right corner</td>
                  <td>
                    <iframe width="640" height="360"
                      src="https://www.youtube.com/embed/N0ZTQq3G37A"
                      frameborder="0" allowfullscreen>
                    </iframe>
                  </td>
                </tr>
                <tr>
                  <td scope="row">Put the carrot and hotdog in pot</td>
                  <td>
                    <iframe width="640" height="360"
                      src="https://www.youtube.com/embed/QigpozIXbQ0"
                      frameborder="0" allowfullscreen>
                    </iframe>
                  </td>
                </tr>
                <tr>
                  <td scope="row">Put the blue cube on the plate</td>
                  <td>
                    <iframe width="640" height="360"
                      src="https://www.youtube.com/embed/Xajw9eaB940"
                      frameborder="0" allowfullscreen>
                    </iframe>
                  </td>
                </tr>
                <tr>
                  <td scope="row">Put banana in pot</td>
                  <td>
                    <iframe width="640" height="360"
                      src="https://www.youtube.com/embed/YF6RH24j5nI"
                      frameborder="0" allowfullscreen>
                    </iframe>
                  </td>
                </tr>
                <tr>
                  <td scope="row">Put the red bottle and the hamburger in the pan</td>
                  <td>
                    <iframe width="640" height="360"
                      src="https://www.youtube.com/embed/ftHc9aISAQw"
                      frameborder="0" allowfullscreen>
                    </iframe>
                  </td>
                </tr>
              </tbody>
            </table>




            <h2 id="Acknowledgement">
              <font color="000093">Acknowledgement</font>
            </h2>
            <div class="container">
              <p>
                This website is created based on <a href = "https://github.com/AudioLDM/AudioLDM.github.io."> https://github.com/AudioLDM/AudioLDM.github.io </a>
              </p>
            </div> 
          </section>
        </article>
      </main>

    </div>
</font>

    <script>
      (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
          (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date(); a = s.createElement(o),
          m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
      })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
      ga('create', 'UA-139981676-1', 'auto');
      ga('send', 'pageview');
    </script>

    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>



    <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
         HTML: ["input/TeX","output/HTML-CSS"],
         TeX: {
                Macros: {
                         bm: ["\\boldsymbol{#1}", 1],
                         argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                         argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
                extensions: ["AMSmath.js","AMSsymbols.js"],
                equationNumbers: { autoNumber: "AMS" } },
         extensions: ["tex2jax.js"],
         jax: ["input/TeX","output/HTML-CSS"],
         tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true },
         "HTML-CSS": { availableFonts: ["TeX"],
                       linebreaks: { automatic: true } }
     });
 </script>

    <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       tex2jax: {
         skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
       }
     });
 </script>

    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
      </script>





</html>
